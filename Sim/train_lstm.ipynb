{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved LSTM Training (Capturing Traffic Spikes)\n",
    "This notebook implements advanced techniques to solve the \"flat-line\" prediction problem common in sparse traffic data:\n",
    "1. **Feature Engineering:** Added 5-minute and 15-minute rolling averages to provide the model with local density context.\n",
    "2. **Weighted MSE Loss:** Penalizes errors on non-zero traffic counts more heavily to prevent the model from simply predicting the mean.\n",
    "3. **Cyclical Time Features:** Encodes the time of day using Sine/Cosine transforms to help the LSTM understand the 24-hour cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Engineering\n",
    "Adding rolling averages and cyclical time features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('lstm_training_data.csv')\n",
    "\n",
    "# 1. Rolling Averages (Capture local density)\n",
    "for d in ['North', 'South', 'East', 'West']:\n",
    "    df[f'{d}_5m_avg'] = df[d].rolling(window=5).mean().fillna(0)\n",
    "    df[f'{d}_15m_avg'] = df[d].rolling(window=15).mean().fillna(0)\n",
    "\n",
    "# 2. Cyclical Time Features (Minute of day 0-1439)\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['time_index'] / 1440)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['time_index'] / 1440)\n",
    "\n",
    "features = [\n",
    "    'North', 'South', 'East', 'West', \n",
    "    'North_5m_avg', 'South_5m_avg', 'East_5m_avg', 'West_5m_avg',\n",
    "    'North_15m_avg', 'South_15m_avg', 'East_15m_avg', 'West_15m_avg',\n",
    "    'hour_sin', 'hour_cos', 'day_of_week'\n",
    "]\n",
    "targets = [\n",
    "    'target_count_North', 'target_count_South', 'target_count_East', 'target_count_West',\n",
    "    'target_score_North', 'target_score_South', 'target_score_East', 'target_score_West'\n",
    "]\n",
    "\n",
    "split_idx = int(len(df) * 0.8)\n",
    "train_df = df.iloc[:split_idx].copy()\n",
    "test_df = df.iloc[split_idx:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_features = MinMaxScaler()\n",
    "scaler_targets = MinMaxScaler()\n",
    "\n",
    "train_features_scaled = scaler_features.fit_transform(train_df[features])\n",
    "train_targets_scaled = scaler_targets.fit_transform(train_df[targets])\n",
    "test_features_scaled = scaler_features.transform(test_df[features])\n",
    "test_targets_scaled = scaler_targets.transform(test_df[targets])\n",
    "\n",
    "joblib.dump(scaler_features, 'scaler_features.pkl')\n",
    "joblib.dump(scaler_targets, 'scaler_targets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficDataset(Dataset):\n",
    "    def __init__(self, features, targets, lookback=60):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.targets = torch.FloatTensor(targets)\n",
    "        self.lookback = lookback\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features) - self.lookback\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx : idx + self.lookback]\n",
    "        y = self.targets[idx + self.lookback - 1]\n",
    "        return x, y\n",
    "\n",
    "LOOKBACK = 60\n",
    "train_dataset = TrafficDataset(train_features_scaled, train_targets_scaled, LOOKBACK)\n",
    "test_dataset = TrafficDataset(test_features_scaled, test_targets_scaled, LOOKBACK)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Weighted Loss Function\n",
    "We penalize error on samples where traffic is present higher than on empty intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse_loss(inputs, targets, weight=5.0):\n",
    "    \"\"\"Weights the loss more heavily when the target is non-zero.\"\"\"\n",
    "    loss = (inputs - targets) ** 2\n",
    "    # Apply weight where targets are > 0.05 (normalized)\n",
    "    weights = torch.where(targets > 0.05, torch.tensor(weight).to(targets.device), torch.tensor(1.0).to(targets.device))\n",
    "    return (loss * weights).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=3):\n",
    "        super(TrafficLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=0.3)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TrafficLSTM(len(features), 128, len(targets)).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for bx, by in train_loader:\n",
    "        bx, by = bx.to(device), by.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(bx)\n",
    "        loss = weighted_mse_loss(pred, by)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch} Loss: {total_loss/len(train_loader):.6f}\")\n",
    "\n",
    "torch.save(model.state_dict(), 'traffic_lstm_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "Verify if the model now captures the spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x_sample, y_sample = next(iter(test_loader))\n",
    "with torch.no_grad():\n",
    "    preds = model(x_sample.to(device)).cpu().numpy()\n",
    "\n",
    "# Inverse transform to original scale for plotting\n",
    "preds_rescaled = scaler_targets.inverse_transform(preds)\n",
    "actual_rescaled = scaler_targets.inverse_transform(y_sample.numpy())\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(actual_rescaled[:200, 0], label='Actual (North)')\n",
    "plt.plot(preds_rescaled[:200, 0], label='Predicted (North)', alpha=0.8)\n",
    "plt.title('Actual vs Predicted Traffic Count (North)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": { "name": "ipython", "version": 3 },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
